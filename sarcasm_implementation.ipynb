{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sarcasm_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/japeshmethuku17/Sarcasm-Detection/blob/master/sarcasm_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuDel0PNTX13",
        "colab_type": "text"
      },
      "source": [
        "# **Sarcasm detection using Natural Language Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwa3LgQlUd26",
        "colab_type": "text"
      },
      "source": [
        "Run the next cell to ensure TensorFlow v2.x exists in your Google Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gs9htvM7n_x",
        "outputId": "1a264ae3-53ea-4f14-867b-66193c686db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "  print(\"Version available\")\n",
        "except Exception:\n",
        "  pass\n",
        "  print(\"Version not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYYDvoskkE61",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eJSTTYnkJQd",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leDZ-uHLU0Wg",
        "colab_type": "text"
      },
      "source": [
        "This method is used to retreive the dataset. The json file is then loaded into the Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BQVuQrZNkPn9",
        "outputId": "b4208b78-e9d6-4001-875d-77302392c349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-11 17:53:52--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-06-11 17:53:52 (146 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cJimBURJ9_",
        "colab_type": "text"
      },
      "source": [
        "Processing the dataset, the columns 'headline' and 'is_sarcastic' is important to us. There is another column named 'article_link' and it is not significant at this point. Our goal is to predict the sarcasm using the headlines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oaLaaqhNkUPd",
        "colab": {}
      },
      "source": [
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYieIIgIRuj4",
        "colab_type": "text"
      },
      "source": [
        "We are splitting the dataset into training and testing sets using the method shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1sD-7v0kYWk",
        "colab": {}
      },
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqPijokebU8Y",
        "colab_type": "text"
      },
      "source": [
        "The Machine Learning approach requires numerical feature vectors to perform a task. The idea of pre-processing the text data is to make the data ideal for a Machine Learning algorithm to work. The preprocessing can include converting the entire text data into uppercase or lowercase, this creates a uniformity and the entire text data is treated in the same fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eptayW2IcEm1",
        "colab_type": "text"
      },
      "source": [
        "**Tokenization:** This process is used to convert the normal text strings into a list of tokens. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj1jizJUdGlp",
        "colab_type": "text"
      },
      "source": [
        "**Removal of noise:** Something that can't be regarded as a number or a letter is removed before feeding the data into the NLP model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Ou9RYkdX6U",
        "colab_type": "text"
      },
      "source": [
        "**Removal of stop words:** Removal of common words that add very little meaning to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3u8UB0MCkZ5N",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GrAlWBKf99Ya",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjC7m5vVeN3W",
        "colab_type": "text"
      },
      "source": [
        "Create a neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FufaT4vlkiDE",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new2HTfSeT0y",
        "colab_type": "text"
      },
      "source": [
        "Display the structure of model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfDt1hmYkiys",
        "outputId": "6863769f-2327-44da-f9d5-432ac816bdea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 160,433\n",
            "Trainable params: 160,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3abspW0WeYXb",
        "colab_type": "text"
      },
      "source": [
        "Train the model for 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2DTKQFf1kkyc",
        "outputId": "69651b7e-081e-4c52-d7ee-51160d8e3600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 4s - loss: 0.6708 - accuracy: 0.5807 - val_loss: 0.6010 - val_accuracy: 0.6350\n",
            "Epoch 2/30\n",
            "625/625 - 3s - loss: 0.4354 - accuracy: 0.8302 - val_loss: 0.3893 - val_accuracy: 0.8326\n",
            "Epoch 3/30\n",
            "625/625 - 3s - loss: 0.3106 - accuracy: 0.8755 - val_loss: 0.3566 - val_accuracy: 0.8436\n",
            "Epoch 4/30\n",
            "625/625 - 3s - loss: 0.2578 - accuracy: 0.9001 - val_loss: 0.3457 - val_accuracy: 0.8542\n",
            "Epoch 5/30\n",
            "625/625 - 3s - loss: 0.2236 - accuracy: 0.9137 - val_loss: 0.3433 - val_accuracy: 0.8533\n",
            "Epoch 6/30\n",
            "625/625 - 3s - loss: 0.1952 - accuracy: 0.9251 - val_loss: 0.3562 - val_accuracy: 0.8489\n",
            "Epoch 7/30\n",
            "625/625 - 3s - loss: 0.1730 - accuracy: 0.9339 - val_loss: 0.3691 - val_accuracy: 0.8481\n",
            "Epoch 8/30\n",
            "625/625 - 3s - loss: 0.1554 - accuracy: 0.9420 - val_loss: 0.3794 - val_accuracy: 0.8521\n",
            "Epoch 9/30\n",
            "625/625 - 3s - loss: 0.1399 - accuracy: 0.9493 - val_loss: 0.3967 - val_accuracy: 0.8521\n",
            "Epoch 10/30\n",
            "625/625 - 3s - loss: 0.1283 - accuracy: 0.9557 - val_loss: 0.4175 - val_accuracy: 0.8502\n",
            "Epoch 11/30\n",
            "625/625 - 3s - loss: 0.1141 - accuracy: 0.9613 - val_loss: 0.4390 - val_accuracy: 0.8475\n",
            "Epoch 12/30\n",
            "625/625 - 3s - loss: 0.1044 - accuracy: 0.9643 - val_loss: 0.4626 - val_accuracy: 0.8441\n",
            "Epoch 13/30\n",
            "625/625 - 3s - loss: 0.0934 - accuracy: 0.9689 - val_loss: 0.4927 - val_accuracy: 0.8411\n",
            "Epoch 14/30\n",
            "625/625 - 3s - loss: 0.0857 - accuracy: 0.9728 - val_loss: 0.5357 - val_accuracy: 0.8366\n",
            "Epoch 15/30\n",
            "625/625 - 3s - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.5881 - val_accuracy: 0.8295\n",
            "Epoch 16/30\n",
            "625/625 - 4s - loss: 0.0742 - accuracy: 0.9753 - val_loss: 0.5750 - val_accuracy: 0.8384\n",
            "Epoch 17/30\n",
            "625/625 - 3s - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.6041 - val_accuracy: 0.8338\n",
            "Epoch 18/30\n",
            "625/625 - 3s - loss: 0.0607 - accuracy: 0.9802 - val_loss: 0.6356 - val_accuracy: 0.8304\n",
            "Epoch 19/30\n",
            "625/625 - 3s - loss: 0.0545 - accuracy: 0.9837 - val_loss: 0.6718 - val_accuracy: 0.8302\n",
            "Epoch 20/30\n",
            "625/625 - 3s - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.7024 - val_accuracy: 0.8267\n",
            "Epoch 21/30\n",
            "625/625 - 3s - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.7584 - val_accuracy: 0.8220\n",
            "Epoch 22/30\n",
            "625/625 - 3s - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.7684 - val_accuracy: 0.8238\n",
            "Epoch 23/30\n",
            "625/625 - 4s - loss: 0.0393 - accuracy: 0.9886 - val_loss: 0.8087 - val_accuracy: 0.8225\n",
            "Epoch 24/30\n",
            "625/625 - 3s - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.8432 - val_accuracy: 0.8186\n",
            "Epoch 25/30\n",
            "625/625 - 3s - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.8765 - val_accuracy: 0.8204\n",
            "Epoch 26/30\n",
            "625/625 - 3s - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.9188 - val_accuracy: 0.8173\n",
            "Epoch 27/30\n",
            "625/625 - 3s - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.9510 - val_accuracy: 0.8170\n",
            "Epoch 28/30\n",
            "625/625 - 3s - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.9883 - val_accuracy: 0.8161\n",
            "Epoch 29/30\n",
            "625/625 - 3s - loss: 0.0252 - accuracy: 0.9926 - val_loss: 1.0329 - val_accuracy: 0.8117\n",
            "Epoch 30/30\n",
            "625/625 - 3s - loss: 0.0234 - accuracy: 0.9934 - val_loss: 1.0807 - val_accuracy: 0.8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SBdAZAenvzL",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_sentence(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "decode_sentence(training_padded[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9MqihtEkzQ9",
        "outputId": "d8d5a3c0-3e5f-46c3-ceb7-439d5ab821b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LoBXVffknldU",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvyWQmz0ek3_",
        "colab_type": "text"
      },
      "source": [
        "Making predictions on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cG8-ArY-qDcz",
        "outputId": "15c411b2-6c88-418d-8d7a-db4f6919e7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sentence = [\"Mirrors can’t talk, lucky for you they can’t laugh either\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "result=model.predict(padded)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999863]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YfpNneQeppI",
        "colab_type": "text"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ff7eY3UE56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "model.save(\"saved_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqOL3OKeudd",
        "colab_type": "text"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmA0Np0sUlst",
        "colab_type": "code",
        "outputId": "bd5bde53-5dea-4ab8-e248-d979027f35ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# opening and store file in a variable\n",
        "\n",
        "json_file = open('model.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "# use Keras model_from_json to make a loaded model\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "\n",
        "loaded_model.load_weights(\"saved_model.h5\")\n",
        "print(\"Loaded Model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}